\chapter{Serveur}

\section{Architecture}

\par Afin de garantir la bonne compréhension des différents termes techniques qui vont suivre, un lexique donnant toutes les définitions nécessaire est disponible en annexe.
\\

\par L’application web vise à être utilisée par des étudiants, certaines conditions de sécurité doivent donc être respectées.
 
\par Les différents programmes doivent pouvoir être lancés sur un environnement vierge indépendant et, bien sûr, isolés du serveur d’exécution afin de prévenir toute corruption de données ou problème de sécurité. Pour répondre à cette problématique, nous nous sommes tournés vers une technique encore jeune et prometteuse : la conteneurisation. Cette technique peut être utilisée via différentes technologies, nous avons choisi l’un des leader du marché : Docker.

\par Docker est une technologie en renouvellement permanent, nous l'avons choisie pour plusieurs raisons.
\par Docker nous est enseigné en option dans notre cursus à l’Université d'Angers et est aussi accessible et documenté. La communauté de ce dernier est très importante. Cela nous donne l’avantage de compléter nos cours en trouvant des solutions à des problèmes réguliers sur des forums, tutoriels et autres outils communautaires.
\\

\par La conteneurisation répond à nos critères d’environnement puisqu’elle permet de créer un espace propre indépendant et sans incidence sur l’environnement qui héberge le \gls{service} pour chaque exécutions. Grâce à cette technique nous avons pu gérer les problèmes de sécurité et d’allocation de ressources. Nous avons choisi la conteneurisation plutôt que les machines virtuelles car elle a l’avantage d’être plus légère mais aussi plus malléable.  

\par L’architecture du site se fait en plusieurs étapes. Actuellement, nous avons une architecture en place ( version béta ) et une architecture définitive avec plusieurs points nécessitant une étude de produit plus poussée pour la mise en place de l’architecture définitive.

\subsection{Architecture actuelle du site}

\par Actuellement le site utilise deux serveurs : un serveur pour l’hébergement du site et un autre pour l’exécution des différents programmes créés par les étudiants. Docker permet de créer des conteneurs éphémères sans persistance de données à partir d’une image officielles (présentes dans le catalogue de docker) ou d’une image personnelle générée à partir d’un dockerfile. De cette manière, les dockerfiles sont envoyés au serveur et les images sont générées quotidiennement afin de s’assurer de la bonne version de ces dernières. Chaque langage utilisé par les étudiants utilise une image unique qui lui est propre, de cette façon les images sont plus légères, plus rapides à la génération et ne possèdent que les paquets et applications nécessaires au bon fonctionnement du langage utilisé. 

\par Pour la version beta du site la communication entre l’application web et le serveur d'exécution s’effectue par SSH. Cette connexion permet l'envoi des instructions  d'exécution du conteneur et de la manière pour récupérer le fichier à compiler généré par l’application web, de cette manière la gestion et la création des conteneur est dynamique.

\subsection{Architecture finale}

\par Le client a exprimé le besoin de pouvoir utiliser plusieurs serveurs répartis sur tous le territoire pour les exécutions des programmes avec un système de load-balancing pour répartir les charges.
Cette architecture a été pensée afin de répondre à cette nécessité et pour assurer une haute disponibilité et respecter la bonne utilisation des principes de docker.

\par Dans sa version finale, l’application n’aura plus besoin d’un serveur d’hébergement, l’application entière sera conteneurisée sous forme de services : un service pour la partie web, un service pour la base de données. L’exécution des conteneurs se fera aussi sous forme de services.

\subsubsection{Avantages de l'architecture}

\par L’application sera accessible en haute disponibilité. En effet, de cette façon, les différents services pourront posséder un certain nombre de répliques et pourront gérer le load-balancing. Docker gérera la synchronisation des différentes répliques de façon automatique. Aussi, si l’une des répliques n’est plus actives, une autre est automatiquement créée ainsi si un serveur vient à tomber, l’application ne sera pas impactée. 

\par Le fait de passer toute l’application sous forme de service permet également de créer un composerfile. Ce fichier permet de lancer les différents services de l’application simultanément mais également de les paramétrer. Cela permet d’être sûr que tous les services sont lancés et ont la bonne configuration, et également de garder une trace des versions.

\par Un essaim docker va être mis en place. Tous les serveurs utilisés par l’application feront partie de l’essaim, cela permettra de lier les serveurs entre eux afin de mettre en place le load-balancing.

\par La mise en place d’une telle structure soulève plusieurs questions.

	\subsubsection{Quelle est la configuration des différents serveurs ?} 

\par Docker est une technologie dite portable mais comme évoqué précédemment cette technologie est encore jeune et possède nombre de limites pour le moment. Pour assurer un fonctionnement identique et sans problèmes des images entre plusieurs serveurs, il faut que ces dernières aient la même configuration (même version de docker, même kernel, et même configuration système que docker pourrait exploiter, comme la prise en charge de la mémoire swap). 

	\subsubsection{Comment gérer la communication des conteneurs entre les différents serveurs sur des réseaux différents ?} 

\par Docker gère les répliques des services, le reverse proxy ainsi que les différents services SSH. Cependant, si les serveurs ne sont pas sur le même réseau, la communication peut vite devenir problématique. Comment assurer la sécurité ? Comment prioriser le serveur le plus proche physiquement afin de limiter la communication et avoir une vitesse maximale ? Faut-il mettre en place un serveur de communication entre les services au travers des serveurs de l’essaim ? Le principe de communication vers un conteneur à travers un service sur un essaim reste encore assez flou à l’heure actuelle avec docker. 

	\subsubsection{Quel service utiliser pour mettre en place l’essaim et le load-balancing ?}

\par Actuellement, deux alternatives dominent le marché : Kubernetes et Docker swarm. Nous avons tenté de mettre en place Docker swarm mais plusieurs problèmes sont apparus. \\

\par Deux façons de faire sont possibles; soit ajouter les serveurs directement à l’essaim soit créer des \gls{dockermachine}s sur les serveurs que l’on ajoute ensuite. Les machines dockers permettent de créer un sous réseau par hôte et d’améliorer la sécurité. Une fois les services définis et l’essaim en place, nous nous sommes rendus compte que la communication entre les service n’était pas aussi aisée que ce que l’on pouvait penser. Après avoir parcouru la documentation de docker au sujet des essaims, nous nous sommes aperçus que la communication inter-services via l’\gls{essaim} était peu répandue et assez complexe. La mise en place d’un réseau de communication via Consul a été testée mais le temps restant ne nous a pas permis d’aller au bout de cet essai ni de l’étudier en profondeur. Ces différents problèmes ont remis en question l’utilisation de docker swarm. Une étude des capacités de Docker swarm et de Kurbernetes est nécessaire afin de déterminer laquelle est la plus à même de répondre à nos besoins.

\subsubsection{Les avantages de cette architecture}

\par Cette architecture permet de définir notre application en micro service avec une charge répartie sur plusieurs serveurs. Cela permet de rajouter des ressources au besoin. Elle permet d’avoir une application en haute disponibilité : la gestion des micro service permet de minimiser la panne en cas de problème sur l’un ou l’autre des micro service mais permet également la réplique sur les serveurs de façon à ne pas avoir de coupure si l’un des serveur n’est plus disponible. Les conteneurs permettent d’avoir une sécurité supplémentaire à l’aide de sous-réseaux et d’environnement sans impact sur le serveur d’exécution. L’utilisation de micro service avec un orchestrateur de \gls{conteneur} tel que Kubernetes ou Docker swarm permet d’avoir une grande partie de la communication et de la sécurité gérée par ce dernier.   

\subsection{Problèmes rencontrés} 

\par Afin de correspondre aux besoins du client mais aussi d’optimiser la sécurité et l'accessibilité, l’architecture initiale du site a dû être divisée en deux étapes : une architecture basique avec la mise en place d’un système de conteneur et une communication temporaire. L’architecture temporaire a été pensée afin de minimiser les changements lors du passage à l’architecture envisagée. La communication a poser des soucis, notamment l’ouverture d’un socket SHH qui vient créer le container et ne laisse pas l’étudiant accéder au serveur mais uniquement le conteneur.

\par Les différentes configurations de sécurité du réseau de l’Université d’Angers ont été très dérangeant notamment lors de la génération des images grâce au \gls{dockerfile}. L’utilisation des services SSH étant bloqué, il a également été compliqué de mettre en place la connexion SSH de la version beta de l’application. 